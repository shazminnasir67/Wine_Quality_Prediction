{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd9ad3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Wine Quality Prediction - Model Training\n",
    "# This notebook trains a model to predict wine quality (1-10 scale)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For this example, we'll create synthetic wine data since we need to avoid dataset conflicts\n",
    "# In real implementation, you would use: wine_data = pd.read_csv('winequality.csv')\n",
    "\n",
    "# Create synthetic wine quality data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate features similar to wine dataset\n",
    "data = {\n",
    "    'fixed_acidity': np.random.normal(7.5, 1.5, n_samples),\n",
    "    'volatile_acidity': np.random.normal(0.4, 0.2, n_samples),\n",
    "    'citric_acid': np.random.normal(0.3, 0.15, n_samples),\n",
    "    'residual_sugar': np.random.normal(5, 3, n_samples),\n",
    "    'chlorides': np.random.normal(0.05, 0.02, n_samples),\n",
    "    'free_sulfur_dioxide': np.random.normal(30, 15, n_samples),\n",
    "    'total_sulfur_dioxide': np.random.normal(120, 40, n_samples),\n",
    "    'density': np.random.normal(0.995, 0.003, n_samples),\n",
    "    'pH': np.random.normal(3.2, 0.3, n_samples),\n",
    "    'sulphates': np.random.normal(0.6, 0.2, n_samples),\n",
    "    'alcohol': np.random.normal(10.5, 1.5, n_samples)\n",
    "}\n",
    "\n",
    "# Create target variable (wine quality 3-9, with 6 being most common)\n",
    "quality_base = (\n",
    "    0.3 * data['alcohol'] + \n",
    "    0.2 * (10 - data['volatile_acidity']) + \n",
    "    0.1 * data['citric_acid'] + \n",
    "    0.1 * data['sulphates'] + \n",
    "    np.random.normal(0, 0.5, n_samples)\n",
    ")\n",
    "quality_normalized = (quality_base - quality_base.min()) / (quality_base.max() - quality_base.min())\n",
    "wine_quality = np.round(3 + quality_normalized * 6).astype(int)\n",
    "data['quality'] = wine_quality\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Wine Quality Dataset Created\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nQuality distribution:\")\n",
    "print(df['quality'].value_counts().sort_index())\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Start MLflow experiment\n",
    "mlflow.set_experiment(\"wine_quality_prediction\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Model parameters\n",
    "    n_estimators = 100\n",
    "    max_depth = 10\n",
    "    random_state = 42\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestRegressor\")\n",
    "    mlflow.log_param(\"feature_scaling\", \"StandardScaler\")\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Training Random Forest model...\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    training_time = (datetime.now() - start_time).total_seconds()\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "    mlflow.log_metric(\"training_time\", training_time)\n",
    "    \n",
    "    print(f\"\\nModel Performance:\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "    print(f\"RÂ² Score: {r2:.4f}\")\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        model, \n",
    "        \"wine_quality_model\",\n",
    "        registered_model_name=\"WineQualityPredictor\"\n",
    "    )\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 5 Most Important Features:\")\n",
    "    print(feature_importance.head())\n",
    "\n",
    "# Save the model and scaler locally\n",
    "print(\"\\nSaving model and scaler...\")\n",
    "with open('../ml/model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('../ml/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save feature names for the API\n",
    "feature_names = list(X.columns)\n",
    "with open('../ml/feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_names, f)\n",
    "\n",
    "print(\"Model training completed successfully!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"- ../ml/model.pkl\")\n",
    "print(\"- ../ml/scaler.pkl\") \n",
    "print(\"- ../ml/feature_names.pkl\")\n",
    "\n",
    "# Display sample predictions\n",
    "print(f\"\\nSample Predictions (first 10 test samples):\")\n",
    "for i in range(min(10, len(y_test))):\n",
    "    print(f\"Actual: {y_test.iloc[i]}, Predicted: {y_pred[i]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
